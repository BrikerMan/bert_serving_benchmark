version: "3.6"

services:
  tf_serving:
    image: "tensorflow/serving:2.2.0"
    container_name: tf_serving
    ports:
      - target: 8501
        published: 8501
        protocol: tcp
    volumes:
      - ../data/bert_saved_model:/models/bert
    environment:
      MODEL_NAME: bert

  api:
    build:
      context: ./../
      dockerfile: docker/Dockerfile
    ports:
      - target: ${API_PORT:-5050}
        published: ${API_PORT:-5050}
        protocol: tcp
    container_name: ml_api
    volumes:
      - ../data:/code/data
    tty: true
    environment:
      API_MODULE: ${API_MODULE:-fastapi_app.main}
      WORKER_CLASS: ${WORKER_CLASS:-uvicorn.workers.UvicornWorker}
      WORKER_COUNT: ${WORKER_COUNT:-4}
      LOG_LEVEL: ${LOG_LEVEL:-DEBUG}
      TF_SERVING: ${TF_SERVING:-False}
    healthcheck:
      test: curl --fail http://0.0.0.0:${API_PORT:-5050}/ || exit 1
      interval: 60s
      timeout: 10s
      retries: 10
      start_period: 60s
